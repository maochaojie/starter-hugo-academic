---
title: A series of tuning methods have been released in modelscope.
date: 2022-12-01
math: true
image:
  placement: 2
  caption: ''
---

Lora, Prefix, Prompt, Adapter, SideTuning are the tuning methods for foundational model
tuning and well used in many downstream tasks. We have adopted these methods on basic multi-
modal pretrained model and released the code in [modelscope lib](https://github.com/modelscope/modelscope). 
The model cards can be accessed in [modelscope](https://www.modelscope.cn/models?page=1&tasks=foundation-model-application&type=cv).

Besides, we also propose and release the new methd U-Tuning in modelscope, you can 
use it in [modelscope](https://www.modelscope.cn/models/damo/cv_vitb16_classification_vision-efficient-tuning-utuning).

